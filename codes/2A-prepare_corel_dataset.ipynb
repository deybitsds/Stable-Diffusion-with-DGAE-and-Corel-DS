{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3h5SdxNBj2S"
      },
      "source": [
        "# Prepare Corel Dataset for Stable Diffusion\n",
        "\n",
        "This notebook prepares the Corel dataset for training Stable Diffusion models with LoRA.\n",
        "\n",
        "**Tasks:**\n",
        "1. Load and explore the Corel dataset\n",
        "2. Generate metadata (captions.json) for each class\n",
        "3. Organize data into appropriate folders\n",
        "4. Prepare everything for training and generation notebooks\n",
        "\n",
        "## Instructions for Google Colab\n",
        "\n",
        "1. Upload your Corel dataset to Google Drive or Colab\n",
        "2. Mount Google Drive if needed (see next cell)\n",
        "3. Adjust paths in the Configuration section if necessary\n",
        "4. Run all cells in order\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required dependencies\n",
        "%pip install -q pillow matplotlib numpy\n",
        "print(\"✓ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive (Optional)\n",
        "\n",
        "If your dataset is in Google Drive, uncomment and run this cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment the following lines if you need to mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# print(\"Google Drive mounted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY6NopEzBj2W",
        "outputId": "a60c0fea-c1e4-4596-a5bf-7d9f83affe59"
      },
      "outputs": [],
      "source": [
        "## 1. Install Dependencies\n",
        "\n",
        "Install required packages for dataset preparation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tph-3dh_Bj2X"
      },
      "source": [
        "## 2. Imports and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uIPIIjzBj2Y",
        "outputId": "a9e45bb4-74a8-4a28-8d15-b8fe82bd0a9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import re\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torch\n",
        "\n",
        "# Verify CUDA availability (for reference, this notebook doesn't use GPU)\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✓ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"  (Note: This notebook processes files, GPU not required)\")\n",
        "else:\n",
        "    print(\"ℹ Running on CPU (this notebook doesn't require GPU)\")\n",
        "\n",
        "# ===== CONFIGURATION =====\n",
        "\n",
        "# Base directory (use '/content' for Colab, '.' for local)\n",
        "BASE_DIR = Path('/content/drive/MyDrive/nsl_25.2/t2')  # Change to '.' if running locally\n",
        "\n",
        "# Corel dataset directory\n",
        "# If using Google Drive: '/content/drive/MyDrive/path/to/data/corel'\n",
        "# If uploaded to Colab: '/content/data/corel'\n",
        "COREL_DATA_DIR = BASE_DIR / 'data' / 'corel'\n",
        "\n",
        "# Output directories\n",
        "TRAINING_DATA_DIR = BASE_DIR / 'training_data'\n",
        "COREL_TRAINING_DIR = TRAINING_DATA_DIR / 'corel'\n",
        "FIGS_DIR = BASE_DIR / 'figs'\n",
        "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
        "\n",
        "# ===== END CONFIGURATION =====\n",
        "\n",
        "# Create directories if they don't exist\n",
        "TRAINING_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "COREL_TRAINING_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DIRECTORIES CREATED/VERIFIED\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Corel dataset: {COREL_DATA_DIR}\")\n",
        "print(f\"Training data: {COREL_TRAINING_DIR}\")\n",
        "print(f\"Figures: {FIGS_DIR}\")\n",
        "print(f\"Outputs: {OUTPUT_DIR}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWNzR5J2Bj2Z"
      },
      "source": [
        "## 3. Explore Corel Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KLRAEu6Bj2a",
        "outputId": "ee7ddb8a-cd06-4e66-889e-721ff3ecddda"
      },
      "outputs": [],
      "source": [
        "# Find all PNG images\n",
        "image_files = sorted(glob.glob(str(COREL_DATA_DIR / '*.png')))\n",
        "print(f\"Total images found: {len(image_files)}\")\n",
        "\n",
        "if len(image_files) == 0:\n",
        "    print(f\"ERROR: No PNG files found in {COREL_DATA_DIR}\")\n",
        "    print(\"Please check the path configuration in the previous cell.\")\n",
        "else:\n",
        "    # Analyze class structure\n",
        "    class_distribution = defaultdict(list)\n",
        "    pattern = re.compile(r'^(\\d+)_(\\d+)\\.png$')\n",
        "\n",
        "    for img_path in image_files:\n",
        "        filename = os.path.basename(img_path)\n",
        "        match = pattern.match(filename)\n",
        "        if match:\n",
        "            class_num = int(match.group(1))\n",
        "            example_num = match.group(2)\n",
        "            class_distribution[class_num].append(filename)\n",
        "\n",
        "    # Show class distribution\n",
        "    print(f\"\\nClasses found: {len(class_distribution)}\")\n",
        "    print(\"\\nDistribution by class:\")\n",
        "    for class_num in sorted(class_distribution.keys()):\n",
        "        count = len(class_distribution[class_num])\n",
        "        print(f\"  Class {class_num:04d}: {count} images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FTt8vPZBj2b"
      },
      "source": [
        "## 4. Create classes.txt File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn1pDfBbBj2b",
        "outputId": "5197a243-6c35-4be2-c78b-d2af3d22f90c"
      },
      "outputs": [],
      "source": [
        "# Check if classes.txt exists, otherwise create a generic one\n",
        "classes_file = COREL_DATA_DIR / 'classes.txt'\n",
        "\n",
        "if classes_file.exists():\n",
        "    print(f\"Found classes.txt at {classes_file}\")\n",
        "    with open(classes_file, 'r') as f:\n",
        "        print(\"\\nContent:\")\n",
        "        print(f.read())\n",
        "else:\n",
        "    print(f\"WARNING: classes.txt not found. Creating a generic one...\")\n",
        "\n",
        "    # Create generic names based on class numbers\n",
        "    class_names = {}\n",
        "    for class_num in sorted(class_distribution.keys()):\n",
        "        # Generic names - ADJUST according to your actual dataset\n",
        "        generic_names = [\n",
        "            \"royalguard\", \"beach\", \"mountain\", \"flower\",\n",
        "            \"building\", \"animal\", \"vehicle\", \"person\"\n",
        "        ]\n",
        "        idx = (class_num - 1) % len(generic_names)\n",
        "        class_names[class_num] = generic_names[idx]\n",
        "\n",
        "    # Save classes.txt\n",
        "    with open(classes_file, 'w') as f:\n",
        "        for class_num in sorted(class_names.keys()):\n",
        "            f.write(f\"{class_num} {class_names[class_num]}\\n\")\n",
        "\n",
        "    print(f\"Created classes.txt at {classes_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OifvFuvLBj2c"
      },
      "source": [
        "## 5. Generate captions.json for Each Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dT1XHELBj2c",
        "outputId": "ad6c7bad-b1eb-4e87-9d02-72d32d4e8950"
      },
      "outputs": [],
      "source": [
        "def read_classes(classes_file):\n",
        "    \"\"\"Read classes.txt file and return a dictionary class -> name\"\"\"\n",
        "    class_mapping = {}\n",
        "\n",
        "    with open(classes_file, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            parts = line.split(maxsplit=1)\n",
        "            if len(parts) >= 2:\n",
        "                class_num = int(parts[0])\n",
        "                class_name = parts[1].strip()\n",
        "                class_mapping[class_num] = class_name\n",
        "\n",
        "    return class_mapping\n",
        "\n",
        "def generate_captions_for_class(class_num, class_name, image_files, output_dir):\n",
        "    \"\"\"Generate captions.json for a specific class\"\"\"\n",
        "    class_dir = output_dir / f\"class_{class_num:04d}\"\n",
        "    class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    captions = {}\n",
        "    pattern = re.compile(r'^(\\d+)_(\\d+)\\.png$')\n",
        "\n",
        "    for img_path in image_files:\n",
        "        filename = os.path.basename(img_path)\n",
        "        match = pattern.match(filename)\n",
        "\n",
        "        if match and int(match.group(1)) == class_num:\n",
        "            # Copy image to class folder\n",
        "            dest_path = class_dir / filename\n",
        "            if not dest_path.exists():\n",
        "                shutil.copy2(img_path, dest_path)\n",
        "\n",
        "            # Create descriptive caption\n",
        "            caption = f\"a photo of a {class_name}\"\n",
        "            captions[filename] = caption\n",
        "\n",
        "    # Save captions.json\n",
        "    captions_file = class_dir / 'captions.json'\n",
        "    with open(captions_file, 'w') as f:\n",
        "        json.dump(captions, f, indent=2)\n",
        "\n",
        "    return len(captions), class_dir\n",
        "\n",
        "# Read classes\n",
        "class_mapping = read_classes(classes_file)\n",
        "print(f\"Loaded {len(class_mapping)} classes from classes.txt\")\n",
        "\n",
        "# Generate captions for each class\n",
        "print(\"\\nGenerating captions.json for each class...\")\n",
        "class_dirs = {}\n",
        "\n",
        "for class_num in sorted(class_distribution.keys()):\n",
        "    if class_num in class_mapping:\n",
        "        class_name = class_mapping[class_num]\n",
        "        count, class_dir = generate_captions_for_class(\n",
        "            class_num, class_name, image_files, COREL_TRAINING_DIR\n",
        "        )\n",
        "        class_dirs[class_num] = class_dir\n",
        "        print(f\"  Class {class_num:04d} ({class_name}): {count} images -> {class_dir.name}\")\n",
        "    else:\n",
        "        print(f\"  WARNING: Class {class_num:04d} not found in classes.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X00WI6YJBj2d"
      },
      "source": [
        "## 6. Generate Unified Dataset (All Classes Together)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXlV9xk-Bj2d",
        "outputId": "a05f03df-d9df-4bd7-91d7-fe1b74ebf977"
      },
      "outputs": [],
      "source": [
        "# Option: Create a unified dataset with all classes\n",
        "corel_all_dir = COREL_TRAINING_DIR / 'corel_all'\n",
        "corel_all_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "all_captions = {}\n",
        "pattern = re.compile(r'^(\\d+)_(\\d+)\\.png$')\n",
        "\n",
        "print(\"\\nCreating unified dataset (all classes)...\")\n",
        "for img_path in image_files:\n",
        "    filename = os.path.basename(img_path)\n",
        "    match = pattern.match(filename)\n",
        "\n",
        "    if match:\n",
        "        class_num = int(match.group(1))\n",
        "\n",
        "        if class_num in class_mapping:\n",
        "            class_name = class_mapping[class_num]\n",
        "\n",
        "            # Copy image\n",
        "            dest_path = corel_all_dir / filename\n",
        "            if not dest_path.exists():\n",
        "                shutil.copy2(img_path, dest_path)\n",
        "\n",
        "            # Create caption\n",
        "            caption = f\"a photo of a {class_name}\"\n",
        "            all_captions[filename] = caption\n",
        "\n",
        "# Save unified captions.json\n",
        "captions_file = corel_all_dir / 'captions.json'\n",
        "with open(captions_file, 'w') as f:\n",
        "    json.dump(all_captions, f, indent=2)\n",
        "\n",
        "print(f\"Unified dataset created: {corel_all_dir}\")\n",
        "print(f\"  Total images: {len(all_captions)}\")\n",
        "print(f\"  Captions saved to: {captions_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bENPBLkuBj2d"
      },
      "source": [
        "## 7. Visualize Dataset Samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IIlTICILBj2e",
        "outputId": "e5ed7c3d-aaaa-4f13-ff65-7619380dcdb7"
      },
      "outputs": [],
      "source": [
        "# Visualize a sample from each class\n",
        "n_samples_per_class = 3\n",
        "n_classes = len(class_distribution)\n",
        "\n",
        "fig, axes = plt.subplots(n_classes, n_samples_per_class, figsize=(15, 5*n_classes))\n",
        "if n_classes == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "for class_idx, class_num in enumerate(sorted(class_distribution.keys())[:n_classes]):\n",
        "    class_images = class_distribution[class_num][:n_samples_per_class]\n",
        "    class_name = class_mapping.get(class_num, f\"class_{class_num}\")\n",
        "\n",
        "    for img_idx, img_filename in enumerate(class_images):\n",
        "        img_path = COREL_DATA_DIR / img_filename\n",
        "\n",
        "        if img_path.exists():\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            axes[class_idx, img_idx].imshow(img)\n",
        "            axes[class_idx, img_idx].set_title(f\"{class_name}\\n{img_filename}\", fontsize=10)\n",
        "            axes[class_idx, img_idx].axis('off')\n",
        "\n",
        "plt.suptitle('Corel Dataset Samples by Class', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIGS_DIR / 'corel_dataset_samples.png', dpi=150, bbox_inches='tight')\n",
        "print(f\"Visualization saved to: {FIGS_DIR / 'corel_dataset_samples.png'}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZXjXFHHBj2e"
      },
      "source": [
        "## 8. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM7n37OkBj2e",
        "outputId": "22b7a101-ad33-4fa5-c998-5c8e5833cb28"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"PREPARATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nCorel dataset processed:\")\n",
        "print(f\"  - Total images: {len(image_files)}\")\n",
        "print(f\"  - Classes found: {len(class_distribution)}\")\n",
        "print(f\"\\nStructure created:\")\n",
        "print(f\"  - Unified dataset: {corel_all_dir}\")\n",
        "print(f\"    -> {len(all_captions)} images with captions.json\")\n",
        "print(f\"\\n  - Per-class datasets:\")\n",
        "for class_num, class_dir in sorted(class_dirs.items()):\n",
        "    class_name = class_mapping.get(class_num, 'unknown')\n",
        "    img_count = len(list(class_dir.glob('*.png')))\n",
        "    print(f\"    -> class_{class_num:04d} ({class_name}): {img_count} images\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"NEXT STEPS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n1. To train LoRA with ALL classes:\")\n",
        "print(f\"   Use notebook: 6-train-lora-corel.ipynb\")\n",
        "print(f\"   Set train_data_dir = '{corel_all_dir}'\")\n",
        "print(\"\\n2. To train LoRA per class (recommended if few samples per class):\")\n",
        "for class_num in sorted(class_dirs.keys())[:3]:  # Show only first 3\n",
        "    class_dir = class_dirs[class_num]\n",
        "    print(f\"   Use notebook: 6-train-lora-corel.ipynb\")\n",
        "    print(f\"   Set train_data_dir = '{class_dir}'\")\n",
        "if len(class_dirs) > 3:\n",
        "    print(f\"   ... and {len(class_dirs)-3} more classes\")\n",
        "\n",
        "print(\"\\n3. To generate images with trained LoRA:\")\n",
        "print(f\"   Use notebook: 7-generate-lora-corel.ipynb\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
